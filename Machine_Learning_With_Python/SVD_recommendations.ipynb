{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Recommendation Systems in Machine Learning**\n",
        "\n",
        "**Overview**\n",
        "\n",
        "Recommendation systems (or recommender systems) are a subclass of information filtering systems that seek to predict the preference or rating a user would give to an item. They are widely used in various domains such as e-commerce, entertainment, social media, and content platforms to provide personalized content and improve user experience.\n",
        "\n",
        "**Types of Recommendation Systems**\n",
        "\n",
        "# **1.Content-Based Filtering**\n",
        "\n",
        "**Overview**:\n",
        "\n",
        "Content-based filtering recommends items to users based on the attributes or features of the items and a profile of the user's preferences. It uses the similarity between items' features and the user's preferences to make recommendations.\n",
        "\n",
        "**Key Characteristics:**\n",
        "\n",
        " * Utilizes item features (e.g., genre, keywords, metadata).\n",
        "\n",
        "* Recommends items similar to those liked by the user in the past.\n",
        "* Doesn't require data on other users.\n",
        "* Can provide explanations for recommendations based on item features.\n",
        "* Examples: Recommending movies based on genre preferences, suggesting articles based on content similarity.\n",
        "\n",
        "**Strengths:**\n",
        "\n",
        "\n",
        "\n",
        "*     Doesn't suffer from cold-start problem for new users.\n",
        "\n",
        "*   Can recommend niche or new items based on their features.\n",
        "*  Provides transparent explanations for recommendations.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "* Limited by the quality of item features.\n",
        "* Tends to recommend similar items, which may lead to over-specialization.\n",
        "* Struggles with providing diverse or serendipitous recommendations.\n",
        "\n",
        "# **2. Collaborative Filtering**\n",
        "**Overview:**\n",
        "\n",
        "Collaborative filtering recommends items to users based on the preferences of other users. It identifies users with similar preferences and recommends items liked by those similar users.\n",
        "Key Characteristics:\n",
        "\n",
        "  * Utilizes user-item interactions or ratings.\n",
        "  * Doesn't require item features; relies on user behavior.\n",
        "  * Can capture complex patterns in user preferences.\n",
        "  * Provides serendipitous recommendations based on similarities between users.\n",
        "  * Examples: Recommending movies liked by users with similar movie preferences, suggesting products purchased by users with similar shopping behavior.\n",
        "\n",
        "**Strengths:**\n",
        "\n",
        "  * Can capture complex user preferences without explicit item features.\n",
        "  * Provides serendipitous recommendations by identifying users with similar tastes.\n",
        "  * Effective for recommending new items with limited data.\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "  * Faces the cold-start problem for new users with limited interaction data (The cold start problem in recommendation systems refers to the challenge of making accurate recommendations when there is insufficient data available. This happens when a new user joins the platform, there is little or no information about their preferences or When a new item is added to the catalog or When a recommendation system is newly deployed in a community or platform).\n",
        "  * Suffers from sparsity of user-item interactions in large datasets.\n",
        "  * Scalability challenges for large datasets due to high computational complexity.\n",
        "\n",
        "# 3. **Matrix Factorization Methods**\n",
        "\n",
        "**Overview:**\n",
        "\n",
        "Matrix factorization methods decompose the user-item interaction matrix into latent factors and use them to predict user preferences or item characteristics.\n",
        "Key Characteristics:\n",
        "\n",
        "  * Represents users and items in a lower-dimensional latent space.\n",
        "  * Learns latent factors from user-item interactions.\n",
        "  * Can capture complex user preferences and item characteristics.\n",
        "  * Examples: Singular Value Decomposition (SVD), Alternating Least Squares (ALS), matrix factorization with deep learning.\n",
        "\n",
        "**Strengths:**\n",
        "\n",
        "  * Captures complex patterns in user preferences and item characteristics.\n",
        "  * Effective for handling sparse and high-dimensional datasets.\n",
        "  * Enables efficient computation of recommendations in large-scale systems.\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "  * Requires a large amount of interaction data for accurate modeling.\n",
        "  * Faces challenges with interpretability due to the latent factors.\n",
        "  * May suffer from overfitting in the presence of noise or outliers.\n",
        "\n",
        "#4. **Association Rule Learning**\n",
        "\n",
        "**Overview:**\n",
        "\n",
        "Association rule learning discovers frequent patterns, associations, or relationships among items in transactional datasets. It can be utilized in recommendation systems to generate item recommendations based on past purchasing behavior or interactions.\n",
        "Key Characteristics:\n",
        "\n",
        "  * Discovers associations or rules between items in transactional data.\n",
        "  * Identifies frequent itemsets and generates association rules.\n",
        "  * Often used in conjunction with other recommendation techniques.\n",
        "  * Examples: Recommending products frequently purchased together, suggesting items based on historical transactional data.\n",
        "\n",
        "**Strengths:**\n",
        "\n",
        "  * Provides insights into associations between items in transactional data.\n",
        "  * Effective for generating rules for cross-selling or upselling.\n",
        "  * Can be combined with other recommendation techniques for improved accuracy.\n",
        "\n",
        "**Weaknesses:**\n",
        "\n",
        "  * May generate trivial or spurious rules in noisy datasets.\n",
        "  * Limited to historical transactional data and may not capture evolving preferences.\n",
        "  * Requires careful preprocessing and parameter tuning to produce meaningful rules."
      ],
      "metadata": {
        "id": "Fw4cmNRPVMS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE-5TVu038Rr",
        "outputId": "392303a0-94ce-4f7d-f493-7ade6ef2252b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended items for user 0 : ['Bread', 'Milk', 'Yogurt']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# Given transactions\n",
        "transactions = [[\"Milk\", \"Bread\", \"Eggs\", \"Cheese\", \"Yogurt\", \"Jam\"],\n",
        "                [\"Milk\", \"Bread\", \"Cheese\", \"Yogurt\",  \"Eggs\"],\n",
        "                [\"Milk\", \"Bread\", \"Butter\", \"Juice\", \"Jam\", \"Eggs\"],\n",
        "                [\"Milk\", \"Eggs\", \"Bread\", \"Cheese\", \"Juice\"],\n",
        "                [\"Milk\", \"Bread\", \"Butter\", \"Cheese\", \"Jam\", \"Juice\"],\n",
        "                [\"Milk\", \"Bread\", \"Eggs\", \"Jam\", \"Yogurt\"]]\n",
        "\n",
        "# Create a list of unique items\n",
        "items = list(set(item for sublist in transactions for item in sublist))\n",
        "\n",
        "# Create a dictionary to map items to indices\n",
        "item_to_index = {item: index for index, item in enumerate(items)}\n",
        "index_to_item = {index: item for item, index in item_to_index.items()}\n",
        "\n",
        "# Create a transaction matrix\n",
        "num_transactions = len(transactions)\n",
        "num_items = len(items)\n",
        "transaction_matrix = np.zeros((num_transactions, num_items), dtype=float)  # Change dtype to float\n",
        "\n",
        "for i, transaction in enumerate(transactions):\n",
        "    for item in transaction:\n",
        "        j = item_to_index[item]\n",
        "        transaction_matrix[i, j] = 1\n",
        "\n",
        "# Convert the transaction matrix to a sparse matrix\n",
        "sparse_transaction_matrix = csr_matrix(transaction_matrix)\n",
        "\n",
        "# Perform Singular Value Decomposition (SVD)\n",
        "k = min(num_transactions, num_items) - 1\n",
        "U, Sigma, VT = svds(sparse_transaction_matrix, k=k)\n",
        "\n",
        "# Generate recommendations\n",
        "def recommend_items(user_id, U, Sigma, VT, top_n=3):\n",
        "    user_vector = U[user_id, :]\n",
        "    scores = np.dot(np.dot(user_vector, np.diag(Sigma)), VT)\n",
        "    top_indices = np.argsort(scores)[::-1][:top_n]\n",
        "    top_items = [index_to_item[index] for index in top_indices]\n",
        "    return top_items\n",
        "\n",
        "# Evaluate the model's performance (Example)\n",
        "# Here, we'll evaluate the recommendation for the first user\n",
        "user_id = 0\n",
        "recommended_items = recommend_items(user_id, U, Sigma, VT)\n",
        "print(\"Recommended items for user\", user_id, \":\", recommended_items)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**\n",
        "\n",
        "To evaluate the recommendations made using the Singular Value Decomposition (SVD) model, we typically employ techniques such as **precision**, **recall**, and **F1-score**, or we may calculate metrics like Mean Average Precision **(MAP)**\n",
        "\n",
        "\n",
        "\n",
        "**Precision**: Precision measures the proportion of recommended items that are relevant to the user out of all recommended items. It is calculated as the number of relevant recommendations divided by the total number of recommendations.\n",
        "\\begin{align}\n",
        "        Precision = \\frac{Number\\ of\\ relevant\\ }{Total\\ number\\ of\\ recommendations​}\n",
        "    \\end{align}\n",
        "\n",
        "\n",
        "**Recall**: Recall measures the proportion of relevant items that are recommended out of all relevant items. It is calculated as the number of relevant recommendations divided by the total number of relevant items.\n",
        "\n",
        "\\begin{align}\n",
        "        Recall = \\frac{Number\\ of\\ relevant\\ }{Total\\ number\\ of\\ relevant\\ items​}\n",
        "    \\end{align}\n",
        "\n",
        "**F1-score:** F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall. It is calculated as:\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        "        F1-score = \\frac{2×Precision×Recall }{Precision+Recall​}\n",
        "    \\end{align}\n",
        "\n",
        "Mean Average Precision (MAP): MAP is a measure of the average precision for each user across all users. It is particularly useful for evaluating recommendation systems when the number of recommended items varies across users."
      ],
      "metadata": {
        "id": "wgfA6jL-G20O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's how we can evaluate the model using precision:\n",
        "\n",
        "\n",
        "1.       Prepare Ground Truth Data: Create a ground truth dataset containing\n",
        "\n",
        "2.  Generate Recommendations: Use the SVD model to generate recommendations for each user.\n",
        "\n",
        "3. Generate Recommendations: Use the SVD model to generate recommendations for each user.\n",
        "\n",
        "4. Calculate Precision: For each user, compare the recommended items with the ground truth items and calculate precision.\n",
        "\n",
        "5. Average Precision: Calculate the average precision across all users to get an overall measure of precision for the model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bqnogX94LOL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth = {\n",
        "    0: [\"Milk\", \"Bread\", \"Cheese\"],\n",
        "    1: [\"Bread\", \"Eggs\", \"Jam\", \"Yogurt\"],\n",
        "    # Add more ground truth data for other users if available\n",
        "}\n",
        "\n",
        "# Calculate precision for each user\n",
        "precisions = []\n",
        "for user_id, true_items in ground_truth.items():\n",
        "    recommended_items = recommend_items(user_id, U, Sigma, VT)\n",
        "    relevant_recommended = sum(1 for item in recommended_items if item in true_items)\n",
        "    precision = relevant_recommended / len(recommended_items) if recommended_items else 0\n",
        "    precisions.append(precision)\n",
        "\n",
        "# Average precision across all users\n",
        "avg_precision = sum(precisions) / len(precisions)\n",
        "\n",
        "print(\"Average Precision:\", avg_precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXy0Pvtk8caT",
        "outputId": "938d5842-ea5c-4406-9a46-5b3843c05a04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Precision: 0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume the ground truth items for the user are: ['Milk', 'Bread', 'Eggs'].\n",
        "\n",
        "And the recommendations provided by the model for the same user are: **['Milk', 'Eggs', 'Cheese', 'Yogurt']**.\n",
        "\n",
        "\n",
        "# To calculate precision for this user:\n",
        "\n",
        "\n",
        "  **Number of Relevant Recommendations:** Count the number of items in the recommendations list that are also in the ground truth list.\n",
        "        Relevant recommendations: ['Milk', 'Eggs']\n",
        "        Number of relevant recommendations: 2\n",
        "\n",
        "\n",
        "**Total Number of Recommendations:** Count the total number of items in the recommendations list.\n",
        "        Total number of recommendations: 4\n",
        "\n",
        "\n",
        "**Calculate Precision:**\n",
        "\\begin{align}\n",
        "        Precision = \\frac{Number\\ of\\ relevant\\ }{Total\\ number\\ of\\ recommendations​}\n",
        "    \\end{align}\n",
        "\n",
        "So, for this user, the precision is 0.5, meaning 50% of the recommended items are relevant to the user.\n",
        "\n",
        "This process is repeated for each user, and the average precision across all users gives an overall measure of the model's performance.\n",
        "\n",
        "Similarly, other metrices can also be calculated"
      ],
      "metadata": {
        "id": "fBgbXcKeL6gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "# Example user-movie rating matrix (5 users, 5 movies)\n",
        "R = np.array([\n",
        "    [5, 3, 0, 1, 4],\n",
        "    [4, 0, 0, 1, 3],\n",
        "    [1, 1, 0, 5, 0],\n",
        "    [1, 0, 4, 4, 0],\n",
        "    [0, 1, 5, 4, 0]\n",
        "])\n",
        "\n",
        "# Step 1: Normalize the matrix by subtracting the mean rating of each user\n",
        "user_ratings_mean = np.mean(R, axis=1)\n",
        "R_demeaned = R - user_ratings_mean.reshape(-1, 1)\n",
        "\n",
        "# Step 2: Perform SVD\n",
        "U, sigma, Vt = svds(R_demeaned, k=2)\n",
        "\n",
        "# Convert sigma to a diagonal matrix\n",
        "sigma = np.diag(sigma)\n",
        "\n",
        "# Step 3: Reconstruct the approximated matrix\n",
        "R_approx = np.dot(np.dot(U, sigma), Vt) + user_ratings_mean.reshape(-1, 1)\n",
        "\n",
        "# Print the original and approximated matrices\n",
        "print(\"Original Ratings Matrix:\\n\", R)\n",
        "print(\"\\nApproximated Ratings Matrix (after SVD and reconstruction):\\n\", R_approx)\n",
        "\n",
        "# Step 4: Generate recommendations\n",
        "# For example, let's recommend a movie for User 1 (index 0)\n",
        "user_index = 0\n",
        "# The original ratings of User 1\n",
        "user_ratings = R[user_index, :]\n",
        "# The predicted ratings of User 1\n",
        "predicted_ratings = R_approx[user_index, :]\n",
        "\n",
        "# Recommend movies that User 1 has not rated yet, sorted by predicted rating\n",
        "recommendations = np.argsort(predicted_ratings)[::-1]  # Descending order\n",
        "\n",
        "print(\"\\nRecommendations for User 1:\")\n",
        "for movie_index in recommendations:\n",
        "    if user_ratings[movie_index] == 0:\n",
        "        print(f\"Recommend Movie {movie_index + 1} with predicted rating {predicted_ratings[movie_index]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuZ0hOJ2HRf",
        "outputId": "2c837f54-6afd-4850-96e5-83f16cccd7b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Ratings Matrix:\n",
            " [[5 3 0 1 4]\n",
            " [4 0 0 1 3]\n",
            " [1 1 0 5 0]\n",
            " [1 0 4 4 0]\n",
            " [0 1 5 4 0]]\n",
            "\n",
            "Approximated Ratings Matrix (after SVD and reconstruction):\n",
            " [[ 4.71217085  2.98464243 -0.08949145  1.09184077  4.30083741]\n",
            " [ 3.26623539  1.60738472 -0.72631707  1.24036086  2.6123361 ]\n",
            " [ 1.49530381  0.16670693  0.41411635  4.83870479  0.08516812]\n",
            " [ 0.25261365  1.04113813  3.44055136  4.24256732  0.02312954]\n",
            " [-0.2754878   1.41985923  4.78286572  4.08954728 -0.01678443]]\n",
            "\n",
            "Recommendations for User 1:\n",
            "Recommend Movie 3 with predicted rating -0.09\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Generate recommendations\n",
        "# For example, let's recommend a movie for User 1 (index 0)\n",
        "user_index = 0\n",
        "# The original ratings of User 1\n",
        "user_ratings = R[user_index, :]\n",
        "# The predicted ratings of User 1\n",
        "predicted_ratings = R_approx[user_index, :]\n",
        "\n",
        "# Recommend movies that User 1 has not rated yet, sorted by predicted rating\n",
        "positive_recommendations = [(i, rating) for i, rating in enumerate(predicted_ratings) if user_ratings[i] == 0 and rating > 0]\n",
        "positive_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nRecommendations for User 1:\")\n",
        "for movie_index, rating in positive_recommendations:\n",
        "    print(f\"Recommend Movie {movie_index + 1} with predicted rating {rating:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpzoV4P63h9a",
        "outputId": "1550d1a6-8f7f-4c8a-f8fc-1c43f4cb6262"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendations for User 1:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate MovieLens data and use SVD to generate movie recommendations"
      ],
      "metadata": {
        "id": "9rr8H9rS4e6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}